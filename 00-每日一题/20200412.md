20200412

今天没有每日一题





下面是深度学习party～



![](https://mmbiz.qpic.cn/mmbiz_jpg/5Sgw1ho9PcicgKcvkWA3OxeuB1UweZj3wRDXSwZyfXsLDVjf1gvLOOzvU5JuAxDvTvvkdjWOMdxkia3IzHKyIKQQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

[每日音乐：http://music.163.com/#/m/song?id=1397489326](http://music.163.com/#/m/song?id=1397489326)

### 神经网络的发展历史

神经网络的发展大致经过五个阶段。

第一阶段：模型提出 第一个阶段为 1943～1969 年，是神经网络发展的第一个高潮期。在此期间，科学家们提出了许多神经元模型和学习规则。

在1943年，心理学家Warren McCulloch和数学家Walter Pitts最早描述了一种理想化的人工神经网络，并构建了一种基于简单逻辑运算的计算机制。他们提出的神经网络模型称为MP模型。至此，开启了神经网络研究的序幕。

阿兰·图灵在1948年的论文中描述了一种“B型图灵机”。之后，研究人员将基于赫布型学习的思想应用到“B型图灵机”上。

1951年， McCulloch和Pitts的学生Marvin Minsky建造了第一台神经网络机SNARC。

Marvin Minsky， 1927～2016 年，人工智能领域最重要的领导者和创新者之一，麻省理工学院人工智能实验
室的创始人之一。因其在人工智能领域的贡献， 1969 年获得图灵奖。

Rosenblatt最早提出可以模拟人类感知能力的神经网络模型，并称之为感知器（Perceptron），并提出了一种接近于人类学习过程（迭代、试错）的学习算法。但感知器因其结构过于简单，不能解决简单的异或（XOR）等线性不可分问题。

在这一时期，神经网络以其独特的结构和处理信息的方法，在许多实际应用领域（自动控制领域、模式识别等）中取得了显著的成效。

第二阶段：冰河期 第二阶段为1969年～1983年，为神经网络发展的第一个低谷期。在此期间，神经网络的研究处于长年停滞及低潮状态。

1969年， Marvin Minsky出版《感知机》一书，指出了神经网络的两个关键缺陷：第一个是感知机无法处理异或回路问题；第二个是当时的计算机无法支持处理大型神经网络所需要计算能力。这些论断直接将以感知器为代表的神经网络打入冷宫，导致神经网络的研究进入了十多年的“冰河期”。

1974 年，哈佛大学的 Paul Webos 发明反向传播算法（Backpropagation，BP），但当时未受到应有的重视。
1980 年， Fukushima（福岛邦彦）提出了一种带卷积和子采样操作的多层神经网络： 新知机（Neocognitron）。新知机的提出是受到了动物初级视皮层简单细胞和复杂细胞的感受野的启发。但新知机并没有采用反向传播算法，而是采用了无监督学习的方式来训练，因此没有引起足够的重视。

第三阶段：反向传播算法引起的复兴 第三阶段为1983年～1995年，为神经网络发展的第二个高潮期。这个时期中，反向传播算法重新激发了人们对神经网络的兴趣。

1983年，加州理工学院的物理学家John Hopfield提出了一种用于联想记忆和优化计算的神经网络，称为Hopfield网络。 Hopfield网络在旅行商问题上获得当时最好结果，并引起了轰动。

1984年， Geoffrey Hinton提出一种随机化版本的Hopfield网络，即玻尔兹曼机。

真正引起神经网络第二次研究高潮的是反向传播算法。1986年，David Rumelhart 和 James McClelland 全面分析了连接主义在计算机模拟神经活动中的应用，并重新发明了反向传播算法。 Geoffrey Hinton等人将反向传播算法引入到多层感知器，解决了多层感知器的学习问题，人工神经网络才又重新引起人们的注意，并开始成为新的研究热点。随后， LeCunet al.将反向传播算法引入了卷积神经网络，并在手写体数字识别上取得了很大的成功。反向传播算法是迄今最为成功的神经网络学习算法，不仅用于多层前馈神经网络，还用于其他类型神经网络的训练。

第四阶段：流行度降低 第四个阶段为1995～2006年，在此期间，支持向量机和其他更简单的方法（例如线性分类器）在机器学习领域的流行度逐渐超过了神经网络。

虽然神经网络可以很容易地增加层数、神经元数量，从而构建复杂的网络，但其计算复杂性也会随之增长。当时的计算机性能和数据规模不足以支持训练大规模的神经网络。在20世纪90年代中期，统计学习理论和以支持向量机为代表的机器学习模型开始兴起。相比之下，神经网络的理论基础不清晰、优化困难、可解释性差等缺点更加凸显，神经网络的研究又一次陷入低潮。

第五阶段：深度学习的崛起 2006年， Hinton and Salakhutdinov发现多层前馈神经网络可以先通过逐层预训练，再用反向传播算法进行精调的方式进行有效学习。随着深度的人工神经网络在语音识别和图像分类等任务上的巨大成功，以神经网络为基础的“深度学习”迅速崛起。近年来，随着大规模并行计算以及GPU设备的普及，计算机的计算能力得以大幅提高。此外，可供机器学习的数据规模也越来越大。在计算能力和数据规模的支持下，计算机已经可以训练大规模的人工神经网络。各大科技公司都投入巨资研究深度学习，神经网络迎来第三次高潮。



### 开心一刻

前一期答案：

取3根， 第一根点两头，第二根点一头，第一根烧完为半小时，此时将第二根另一头点燃，烧完获得15分钟。

